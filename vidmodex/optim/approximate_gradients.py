import torch.nn.functional as F
import torch
import numpy as np
import torchvision
import os
from vidmodex.loss.custom_loss import generator_loss

# os.environ["CUDA_VISIBLE_DEVICES"] = "1"

# from cifar10_models import *


def estimate_gradient_objective(
        args, victim_model, victim_transform, clone_model, clone_transform, x, epsilon=1e-7,
        m=5, num_classes=10, device="cpu", pre_x=False):
    # Sampling from unit sphere is the method 3 from this website:
    #  http://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/
    #x = torch.Tensor(np.arange(2*1*7*7).reshape(-1, 1, 7, 7))

    # x is the fake image generated by the query generator; shape :

    # m = 'Number of steps to approximate the gradients'

    clone_model.eval()
    victim_model.eval()
    
    with torch.no_grad():
        # Sample unit noise vector
        N = x.size(0)  # batches (B, C, T, H, W)
        inp_shape = x.shape[1:] # (C, T, H, W) if video or (C, H, W) if image
        if len(inp_shape) == 4:
            # For video based models
            C = x.size(1)  # channels
            Fr = x.size(2)  # frames in video
            S = x.size(3)  # width, height
            dim = S**2 * C  # Fr
            u = np.random.randn(N * m * dim * Fr).reshape(-1, m,Fr, dim)
            d = np.sqrt(np.sum(u ** 2, axis=-1)).reshape(-1, m,Fr, 1)
            u = torch.Tensor(u / d).view(-1, m, C, Fr, S, S )
            # u = u.permute(0, 1, 5, 2, 3, 4)
            # To remove the randomness in the frames of the same video thus the Fr we removed.
            u = torch.cat((u, torch.zeros(N, 1, C,Fr, S, S)),
                        dim=1)
            # (B,M+1, C, T, H, W)
            evaluation_points = (x.view(-1, 1, C, Fr, S, S).cpu() +
                                epsilon * u).view(-1, C, Fr, S, S)  # N * (m + 1)
        elif len(inp_shape) == 3:
            # For image based models
            C = x.size(1)  # channels
            S = x.size(2)
            dim = S**2 * C
            u = np.random.randn(N * m * dim).reshape(-1, m, dim)
            d = np.sqrt(np.sum(u ** 2, axis=-1)).reshape(-1, m, 1)
            u = torch.Tensor(u / d).view(-1, m, C, S, S)
            u = torch.cat((u, torch.zeros(N, 1, C, S, S)),
                        dim=1)
            evaluation_points = (x.view(-1, 1, C, S, S).cpu() +
                                epsilon * u).view(-1, C, S, S)
        else:
            raise ValueError(f"Input shape not supported yet. {inp_shape}")
        
        # Compute the approximation sequentially to allow large values of m
        pred_victim = []
        pred_clone = []
        # Hardcoded value to split the large evaluation_points tensor to fit in GPU
        max_number_points = 16 * 32
        for i in (range(N * m // max_number_points + 1)):
            pts = evaluation_points[i *
                                    max_number_points: min(N*(m+1), (i+1) * max_number_points)]
            pts = pts.to(device)
            pred_victim_pts = victim_model(victim_transform(pts)).detach()
            pred_clone_pts = F.softmax(clone_model(clone_transform(pts)), dim=1)
            pred_victim.append(pred_victim_pts)
            pred_clone.append(pred_clone_pts)
        pred_victim = torch.cat(pred_victim, dim=0).to(device)
        pred_clone = torch.cat(pred_clone, dim=0).to(device)

        u = u.to(device)
        loss_values = generator_loss(args, pred_clone, pred_victim, return_t_logits=False, reduction="none")
        if args.gen_loss == "kl":
            loss_values = loss_values.sum(dim=1).view(-1, m + 1)
        else:
            loss_values = loss_values.mean(dim=1).view(-1, m + 1)
        
        # Compute difference following each direction
        differences = loss_values[:, :-1] - loss_values[:, -1].view(-1, 1)
        differences = differences.view(-1, m, *[1 for _ in range(len(inp_shape))])

        # Formula for Forward Finite Differences
        # [N, M, 1,1,1,1]N M C Fr S S
        gradient_estimates = 1 / epsilon * differences * u[:, :-1]
        if args.forward_differences:
            gradient_estimates *= dim

        if args.gen_loss == "kl":
            gradient_estimates = gradient_estimates.mean(
                dim=1).view(-1, *inp_shape)
        else:
            gradient_estimates = gradient_estimates.mean(
                dim=1).view(-1, *inp_shape) / (num_classes * N)

        clone_model.train()
        loss_G = loss_values[:, -1].mean()
        return gradient_estimates.detach(), loss_G


def compute_gradient(args, victim_model, victim_transform, clone_model, clone_transform, x, pre_x=False, device="cpu"):

    clone_model.eval()
    N = x.size(0)
    x_copy = x.clone().detach().requires_grad_(True)
    x_ = x_copy.to(device)


    pred_victim = victim_model(victim_transform(x_))
    pred_clone = F.softmax(clone_model(clone_transform(x_)), dim=1)

    
    loss_values = generator_loss(args, pred_clone, pred_victim, return_t_logits=False)
    
    loss_values.backward()
    clone_model.train()
    return x_.grad, loss_values


def compute_grad_norms(generator, student):
    G_grad = []
    for n, p in generator.named_parameters():
        if "weight" in n:
            G_grad.append(p.grad.norm().to("cpu"))

    S_grad = []
    for n, p in student.named_parameters():
        if "weight" in n:
            S_grad.append(p.grad.norm().to("cpu"))
    return  np.mean(G_grad), np.mean(S_grad)

def measure_true_grad_norm(args, teacher, teacher_transform, student, student_transform, device, x):
    # Compute true gradient of loss wrt x
    true_grad, _ = compute_gradient(args, teacher, teacher_transform, student, student_transform, x, pre_x=True, device=device)
    # true_grad = true_grad.view(-1, 3072)

    # Compute norm of gradients
    norm_grad = true_grad.norm(2, dim=1).mean().cpu()

    return norm_grad

class Args(dict):
    def __init__(self, **args):
        for k, v in args.items():
            self[k] = v